{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import wfdb\n",
    "from wfdb.io.convert.edf import read_edf,rdedfann\n",
    "import torch\n",
    "from scipy.io import loadmat\n",
    "from scipy.signal import resample\n",
    "import mne\n",
    "from mne.io import concatenate_raws, read_raw_edf\n",
    "import os\n",
    "\n",
    "os.chdir('')\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else  'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [CPSC 2019](http://2019.icbeb.org/Challenge.html)\n",
    "- 500Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load .mat files\n",
    "dataset_path = '../Data'\n",
    "dataset_name = 'cpsc_2019'\n",
    "fs=500\n",
    "root_path = os.path.join(dataset_path,dataset_name,'train/data')\n",
    "save_path = os.path.join(dataset_path,dataset_name,'train_wfdb')\n",
    "if not os.path.exists(save_path):\n",
    "    os.mkdir(save_path)\n",
    "\n",
    "for filename in os.listdir(root_path):\n",
    "    file_path = os.path.join(root_path, filename)\n",
    "    data = loadmat(file_path)\n",
    "    signal = data['ecg']\n",
    "    record_name = filename[:-4]\n",
    "    wfdb.wrsamp(record_name, fs=fs, units=['mV'], sig_name=['ECG'], p_signal=signal,write_dir=save_path)\n",
    "\n",
    "    ann = loadmat(os.path.join(dataset_path,dataset_name,'train/ref',f'R_{filename[5:]}'))\n",
    "    qrs_positions = ann['R_peak'][:,0]\n",
    "    wfdb.wrann(record_name, extension=\"atr\",sample=qrs_positions,symbol=[\"N\"] * len(qrs_positions),write_dir=save_path)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [CPSC 2020](http://icbeb2020.pastconf.com/CSPC2020)\n",
    "- 400Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load .mat files\n",
    "dataset_path = '../Data'\n",
    "dataset_name = 'cpsc_2020'\n",
    "fs=400\n",
    "root_path = os.path.join(dataset_path,dataset_name,'TrainingSet/data')\n",
    "save_path = os.path.join(dataset_path,dataset_name,'train_wfdb')\n",
    "if not os.path.exists(save_path):\n",
    "    os.mkdir(save_path)\n",
    "\n",
    "for filename in os.listdir(root_path):\n",
    "    file_path = os.path.join(root_path, filename)\n",
    "    data = loadmat(file_path)\n",
    "    signal = data['ecg']\n",
    "    record_name = filename[:-4]\n",
    "    wfdb.wrsamp(record_name, fs=fs, units=['mV'], sig_name=['ECG'], p_signal=signal,write_dir=save_path)\n",
    "\n",
    "    ann = loadmat(os.path.join(dataset_path,dataset_name,'TrainingSet/ref',f'R{filename[1:]}'))\n",
    "    qrs_positions = ann['ref'][0][0]\n",
    "    list1_combined = list(zip(qrs_positions[0][:,0], [\"S\"] * len(qrs_positions[0][:,0])))\n",
    "    list2_combined = list(zip(qrs_positions[1][:,0], [\"V\"] * len(qrs_positions[1][:,0])))\n",
    "    qrs_positions = list1_combined+ list2_combined\n",
    "    qrs_positions = sorted(qrs_positions, key=lambda x: x[0])\n",
    "    qrs_positions = np.array(qrs_positions)\n",
    "\n",
    "    wfdb.wrann(f'{record_name}', extension=\"atr\",sample=qrs_positions[:,0].astype(int),symbol=qrs_positions[:,1].astype(str),write_dir=save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADFECGDB\n",
    "1000Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load .mat files\n",
    "dataset_path = '../Data/DetectionDB'\n",
    "dataset_name = 'ADFECGDB'\n",
    "fs=1000\n",
    "root_path = os.path.join(dataset_path,dataset_name,'data')\n",
    "save_path = os.path.join(dataset_path,dataset_name,'train_wfdb')\n",
    "if not os.path.exists(save_path):\n",
    "    os.mkdir(save_path)\n",
    "\n",
    "for filename in os.listdir(root_path):\n",
    "    if filename[-4:] != '.edf':\n",
    "        continue\n",
    "    file_path = os.path.join(root_path, filename)\n",
    "    data = read_raw_edf(file_path)\n",
    "    sig_name = data._raw_extras[0]['ch_names']\n",
    "    units = data._raw_extras[0]['units'].astype(str).tolist()\n",
    "    signal = data[sig_name][0].T\n",
    "    record_name = filename[:-4]\n",
    "    wfdb.wrsamp(record_name, fs=fs, units=units, sig_name=sig_name, p_signal=signal,write_dir=save_path)\n",
    "\n",
    "    qrs_positions = mne.events_from_annotations(data)[0][:,0]\n",
    "    wfdb.wrann(f'{record_name}', extension=\"atr\",sample=qrs_positions.astype(int),symbol=np.full(qrs_positions.shape,\"N\").astype(str),write_dir=save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NIFECGDB\n",
    "1000Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load .mat files\n",
    "dataset_path = '../Data/DetectionDB'\n",
    "dataset_name = 'NIFECGDB'\n",
    "fs=1000\n",
    "root_path = os.path.join(dataset_path,dataset_name,'data')\n",
    "save_path = os.path.join(dataset_path,dataset_name,'train_wfdb')\n",
    "if not os.path.exists(save_path):\n",
    "    os.mkdir(save_path)\n",
    "\n",
    "for filename in os.listdir(root_path):\n",
    "    if filename[-4:] != '.edf':\n",
    "        continue\n",
    "    file_path = os.path.join(root_path, filename)\n",
    "    data = read_raw_edf(file_path)\n",
    "    sig_name = data._raw_extras[0]['ch_names']\n",
    "    units = data._raw_extras[0]['units'].astype(str).tolist()\n",
    "    signal = data[sig_name][0].T\n",
    "    record_name = filename[:-4]\n",
    "    wfdb.wrsamp(record_name, fs=fs, units=units, sig_name=sig_name, p_signal=signal,write_dir=save_path)\n",
    "\n",
    "    qrs_positions = mne.events_from_annotations(data)[0][:,0]\n",
    "    wfdb.wrann(f'{record_name}', extension=\"atr\",sample=qrs_positions.astype(int),symbol=np.full(qrs_positions.shape,\"N\").astype(str),write_dir=save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BA-LABOUR\n",
    "500Hz\n",
    "FECG 1kHz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load .mat files\n",
    "dataset_path = '../Data/DetectionDB'\n",
    "dataset_name = 'BA-LABOUR'\n",
    "fs=500\n",
    "root_path = os.path.join(dataset_path,dataset_name,'data/B1_Pregnancy_dataset')\n",
    "save_path = os.path.join(dataset_path,dataset_name,'train_wfdb/B1_Pregnancy_dataset')\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "for i in range(1,11):\n",
    "    root = os.path.join(root_path, f'B1_Pregnancy_{str(i).zfill(2)}')\n",
    "    signal = pd.read_csv(os.path.join(root, f'B1_abSignals_{str(i).zfill(2)}.txt'),sep='\\t', header=None)\n",
    "    signal = signal.map(lambda x: str(x).replace(\",\", \".\") if isinstance(x, str) else x)\n",
    "    signal = signal.values.astype(float)\n",
    "    sig_name = [f'Abdomen_{i}' for i in range(4)]+[f'indirect_fecg_{i}' for i in range(4)]\n",
    "    record_name = f'B1_Pregnancy_{str(i).zfill(2)}'\n",
    "    wfdb.wrsamp(record_name, fs=fs, units=['mV']*(len(sig_name)), sig_name=sig_name, p_signal=signal,write_dir=save_path)\n",
    "\n",
    "    fetal_qrs_positions = pd.read_csv(os.path.join(root, f'B1_Fetal_R_{str(i).zfill(2)}.txt'),sep='\\t', header=None).values.astype(int)[:,0]\n",
    "    wfdb.wrann(f'{record_name}_Fetal', extension=\"atr\",sample=fetal_qrs_positions,symbol=np.full(fetal_qrs_positions.shape,\"N\").astype(str),write_dir=save_path)\n",
    "\n",
    "    maternal_qrs_positions = pd.read_csv(os.path.join(root, f'B1_Maternal_R_{str(i).zfill(2)}.txt'),sep='\\t', header=None).values.astype(int)[:,0]\n",
    "    wfdb.wrann(f'{record_name}_Maternal', extension=\"atr\",sample=maternal_qrs_positions,symbol=np.full(maternal_qrs_positions.shape,\"N\").astype(str),write_dir=save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import resample\n",
    "\n",
    "# load .mat files\n",
    "dataset_path = '../Data/DetectionDB'\n",
    "dataset_name = 'BA-LABOUR'\n",
    "fs=500\n",
    "root_path = os.path.join(dataset_path,dataset_name,'data/B2_Labour_dataset')\n",
    "save_path = os.path.join(dataset_path,dataset_name,'train_wfdb/B2_Labour_dataset')\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "for i in range(1,11):\n",
    "    root = os.path.join(root_path, f'B2_Labour_{str(i).zfill(2)}')\n",
    "    signal = pd.read_csv(os.path.join(root, f'B2_abSignals_{str(i).zfill(2)}.txt'),sep='\\t', header=None)\n",
    "    signal = signal.map(lambda x: str(x).replace(\",\", \".\") if isinstance(x, str) else x)\n",
    "    signal = signal.values.astype(float)\n",
    "    fecg_signal = pd.read_csv(os.path.join(root, f'B2_dFECG_{str(i).zfill(2)}.txt'),sep='\\t', header=None).map(lambda x: str(x).replace(\",\", \".\") if isinstance(x, str) else x).values.astype(float)\n",
    "    # resample to 500Hz\n",
    "    fecg_signal = resample(fecg_signal,num=len(signal))\n",
    "    signal = np.concatenate([signal,fecg_signal],axis=1)\n",
    "    sig_name = [f'Abdomen_{i}' for i in range(4)]+[f'indirect_fecg_{i}' for i in range(4)] + ['raw_fecg', 'fecg']\n",
    "    record_name = f'B2_Labour_{str(i).zfill(2)}'\n",
    "    wfdb.wrsamp(record_name, fs=fs, units=['mV']*(len(sig_name)), sig_name=sig_name, p_signal=signal,write_dir=save_path)\n",
    "\n",
    "    fetal_qrs_positions = pd.read_csv(os.path.join(root, f'B2_Fetal_R_{str(i).zfill(2)}.txt'),sep='\\t', header=None).values.astype(int)[:,0]//2\n",
    "    wfdb.wrann(f'{record_name}_Fetal', extension=\"atr\",sample=fetal_qrs_positions,symbol=np.full(fetal_qrs_positions.shape,\"N\").astype(str),write_dir=save_path)\n",
    "\n",
    "    maternal_qrs_positions = pd.read_csv(os.path.join(root, f'B2_Maternal_R_{str(i).zfill(2)}.txt'),sep='\\t', header=None).values.astype(int)[:,0]\n",
    "    wfdb.wrann(f'{record_name}_Maternal', extension=\"atr\",sample=maternal_qrs_positions,symbol=np.full(maternal_qrs_positions.shape,\"N\").astype(str),write_dir=save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SensSmartTech "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load .mat files\n",
    "dataset_path = '../Data/GenerationDB'\n",
    "dataset_name = 'SensSmartTech'\n",
    "save_path = os.path.join(dataset_path,dataset_name,'train_wfdb')\n",
    "file_set = set(map(lambda x:x[:-8],os.listdir(os.path.join(dataset_path,dataset_name,'data','WFDB'))))\n",
    "\n",
    "for file_name in file_set:\n",
    "    \n",
    "    ecg_data = wfdb.rdrecord(os.path.join(dataset_path,dataset_name,'data','WFDB',file_name+'_ecg'))\n",
    "    ppg_data = wfdb.rdrecord(os.path.join(dataset_path,dataset_name,'data','WFDB',file_name+'_ppg'))\n",
    "    pcg_data = wfdb.rdrecord(os.path.join(dataset_path,dataset_name,'data','WFDB',file_name+'_pcg'))\n",
    "    sig_name = ecg_data.sig_name+ppg_data.sig_name+pcg_data.sig_name\n",
    "    p_signals = np.concat([ecg_data.p_signal,ppg_data.p_signal,pcg_data.p_signal],axis=1)\n",
    "\n",
    "    wfdb.wrsamp(file_name, fs=ecg_data.fs, units=ecg_data.units+ppg_data.units+pcg_data.units, sig_name=sig_name,comments=ecg_data.comments, p_signal=p_signals,write_dir=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_signals.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DALIA\n",
    "- PPG: 64Hz\n",
    "- ECG: 700Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '../Data/GenerationDB'\n",
    "dataset_name = 'DALIA'\n",
    "ecg_fs = 700\n",
    "ppg_fs = 64\n",
    "std_fs = 100\n",
    "root_path = os.path.join(dataset_path,dataset_name,'PPG_FieldStudy')\n",
    "save_path = os.path.join(dataset_path,dataset_name,'train_wfdb')\n",
    "if not os.path.exists(save_path):\n",
    "    os.mkdir(save_path)\n",
    "\n",
    "for i in range(1,16):\n",
    "    file_name = f'S{i}'\n",
    "    file_path = os.path.join(root_path,file_name,f'{file_name}.pkl')\n",
    "    data = pd.read_pickle(file_path)\n",
    "    ppg = data['signal']['wrist']['BVP']\n",
    "    ecg = data['signal']['chest']['ECG']\n",
    "    std_length = int(ecg.shape[0]//ecg_fs*std_fs)\n",
    "    resampled_ecg = resample(ecg, std_length)\n",
    "    resampled_ppg = resample(ppg, std_length)\n",
    "    p_signals = np.concat([resampled_ecg,resampled_ppg],axis=1)\n",
    "    \n",
    "    wfdb.wrsamp(file_name, fs=std_fs,units=['',''], sig_name=['ECG','PPG'], p_signal=p_signals,write_dir=save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WESAD\n",
    "- PPG: 64Hz\n",
    "- ECG: 700Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '../Data/GenerationDB'\n",
    "dataset_name = 'WESAD'\n",
    "ecg_fs = 700\n",
    "ppg_fs = 64\n",
    "std_fs = 100\n",
    "root_path = os.path.join(dataset_path,dataset_name,'data')\n",
    "save_path = os.path.join(dataset_path,dataset_name,'train_wfdb')\n",
    "if not os.path.exists(save_path):\n",
    "    os.mkdir(save_path)\n",
    "\n",
    "for file_name in os.listdir(root_path):\n",
    "    file_path = os.path.join(root_path,file_name,f'{file_name}.pkl')\n",
    "    data = pd.read_pickle(file_path)\n",
    "    ppg = data['signal']['wrist']['BVP']\n",
    "    ecg = data['signal']['chest']['ECG']\n",
    "    std_length = int(ecg.shape[0]//ecg_fs*std_fs)\n",
    "    resampled_ecg = resample(ecg, std_length)\n",
    "    resampled_ppg = resample(ppg, std_length)\n",
    "    p_signals = np.concat([resampled_ecg,resampled_ppg],axis=1)\n",
    "    \n",
    "    wfdb.wrsamp(file_name, fs=std_fs,units=['',''], sig_name=['ECG','PPG'], p_signal=p_signals,write_dir=save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
